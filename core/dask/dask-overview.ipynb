{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df3a8f0-0ef1-4e50-9d41-afb98c875426",
   "metadata": {},
   "source": [
    "<img src=\"images/dask_horizontal.svg\" align=\"right\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b7e4f-b66d-49c5-8ddd-7c460742878c",
   "metadata": {},
   "source": [
    "# Introducing Dask\n",
    "\n",
    "**First,...**\n",
    "\n",
    "<img src=\"images/should-i-use-dask.png\" width=\"50%\">\n",
    "\n",
    "Dask is a parallel computing library that scales the existing Python libraries. This tutorial will introduce Dask and parallel data analysis more generally.\n",
    "\n",
    "\n",
    "## Learning Objectives \n",
    "\n",
    "- Describe components that make up Dask\n",
    "- Deploy a local Dask Distributed Cluster and access the diagnostics dashboard\n",
    "- Work with `dask.delayed` to parallelize custom functions/workloads\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| Familiarity with Python | Helpful | |\n",
    "\n",
    "\n",
    "- **Time to learn**: *5 minutes*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd1263-b2fe-47b5-9ed1-12c4b3de2240",
   "metadata": {},
   "source": [
    "\n",
    "## Dask Components \n",
    "\n",
    "Dask is composed of two main parts:\n",
    "\n",
    "- **Dask Collections**\n",
    "- **Dynamic Task Scheduling**\n",
    "\n",
    "<img src=\"images/Dask Overview (Light).png\" width=\"80%\">\n",
    "\n",
    "1. High-level collection APIs:\n",
    "  - **Dask Array**: Parallel NumPy Arrays\n",
    "  - **Dask DataFrame**: Parallel Pandas DataFrames\n",
    "  - **Dask Bag**: Parallel lists\n",
    "  - **Dask ML**: Parallel Scikit-learn\n",
    "\n",
    "\n",
    "2. Low-level collection APIs:\n",
    "  - **Dask Delayed**: Lazy parallel objects\n",
    "  - **Dask Futures**: Eager parallel objects\n",
    "\n",
    "\n",
    "3. Task Scheduling\n",
    "  - **Scheduler**: \n",
    "    - creates and manages directed acyclic graphs (DAG)s\n",
    "    - distributes tasks to workers\n",
    "    \n",
    "    \n",
    "    \n",
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Lazy evaluation vs eager evaluation</p>\n",
    "    <ul>\n",
    "        \n",
    "        <li> Lazy evaluation: objects are evaluated just in time when the results are needed </li> \n",
    "    \n",
    "<li>Eager evaluation: objects are evaluated in real time regardless if the results are needed immediately or not </li>\n",
    "    </ul>\n",
    "</div>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587dd62-6873-4056-b606-5806f64e11e7",
   "metadata": {},
   "source": [
    "## Advantages of using Dask\n",
    "\n",
    "- **Familiarity**: Dask collections such as Dask Array, Dask DataFrames provide decent NumPy and Pandas compatible APIs.\n",
    "- **Responsive**: Dask is designed with interactive computing in mind. \n",
    "    - It provides rapid feedback and diagnostics to aid humans\n",
    "- **Scale up and scale down**: It scales well from single machine (laptop) to clusters (100s of machines)\n",
    "    - This ease of transition between single machine to moderate clusters makes it easy for users to prototype their workflows on their local machines and seamlessy transition to a cluster when needed. \n",
    "    - This also gives users a lot of flexibility when choosing the best to deploy and run their workflows. \n",
    "- **Flexibility**: Dask supports interfacing with popular cluster resource managers such as PBS/SLURM/Kubernetes, etc.. with a minimal amount of effort\n",
    "\n",
    "<img src=\"images/Dask Cluster Manager (Light)(1).png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c600b-8fb5-4dfb-aede-d85870fbb9bf",
   "metadata": {},
   "source": [
    "## Task Graphs\n",
    "\n",
    "Dask represents distributed/parallel computations with task graphs, more specifically [directed acyclic graphs](https://en.wikipedia.org/wiki/Directed_acyclic_graph).\n",
    "\n",
    "- A task is a function that you want to call and its corresponding inputs\n",
    "- A task graph is a collection of (1) the functions we want to call + their inputs (2) their dependencies. \n",
    "\n",
    "\n",
    "Directed acyclic graphs are made up of nodes and have a clearly defined start and end, a single traversal path, and no looping \n",
    "\n",
    "<img src=\"images/dask-task-stream.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bccf44-b0e7-4fb4-a06a-e29309e1d868",
   "metadata": {},
   "source": [
    "---\n",
    "## The Dask Squad - Key Players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e8b8e-d868-4948-8e2e-49efe8fc7249",
   "metadata": {},
   "source": [
    "### Dask Client\n",
    "The Client is what interfaces between your Python code and the scheduler - this is the primary API that comes from `dask.distributed`\n",
    "\n",
    "The `dask.distributed` system is composed of a single centralized scheduler and one or more worker processes. [Deploying](https://docs.dask.org/en/latest/setup.html) a remote Dask cluster involves some additional effort. But doing things locally is just involves creating a `LocalCluster` object and connecting this object to a `Client` object, which lets you interact with the \"cluster\" (local threads or processes on your machine). For more information see [here](https://docs.dask.org/en/latest/setup/single-distributed.html). \n",
    "\n",
    "<img src=\"images/Distributed Overview (Light).png\">\n",
    "\n",
    "Note that `LocalCluster()` takes a lot of optional [arguments](https://distributed.dask.org/en/latest/local-cluster.html#api), to configure the number of processes/threads, memory limits and other "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d36df-8994-42ff-b2d6-f81054e9f879",
   "metadata": {},
   "source": [
    "### Dask Schedulers\n",
    "\n",
    "As we have seen so far, Dask allows you to simply construct graphs of tasks with dependencies, as well as have graphs created automatically for you using functional, Numpy or Xarray syntax on data collections. None of this would be very useful, if there weren't also a way to execute these graphs, in a parallel and memory-aware way.\n",
    "\n",
    "Dask comes with four available schedulers:\n",
    "\n",
    "- \"threaded\" (aka \"threading\"): a scheduler backed by a thread pool\n",
    "- \"processes\": a scheduler backed by a process pool\n",
    "- \"single-threaded\" (aka \"sync\"): a synchronous scheduler, good for debugging\n",
    "- distributed: a distributed scheduler for executing graphs on multiple machines, see below.\n",
    "\n",
    "To select one of these for computation, you can specify at the time of asking for a result, e.g.,\n",
    "```python\n",
    "myvalue.compute(scheduler=\"single-threaded\")  # for debugging\n",
    "```\n",
    "\n",
    "You can also set a default scheduler either temporarily\n",
    "```python\n",
    "with dask.config.set(scheduler='processes'):\n",
    "    # set temporarily for this block only\n",
    "    # all compute calls within this block will use the specified scheduler\n",
    "    myvalue.compute()\n",
    "    anothervalue.compute()\n",
    "```\n",
    "\n",
    "Or globally\n",
    "```python\n",
    "# set until further notice\n",
    "dask.config.set(scheduler='processes')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751c57a-5100-4028-adc9-18003e74c082",
   "metadata": {},
   "source": [
    "## Distributed Dask clusters for HPC and Cloud environments\n",
    "\n",
    "Dask can be deployed on distributed infrastructure, such as a an HPC system or a cloud computing system. There is a growing ecosystem of Dask deployment projects that faciliate easy deployment and scaling of Dask clusters on a wide variety of computing systems.\n",
    "\n",
    "### HPC\n",
    "\n",
    "#### Dask Jobqueue (https://jobqueue.dask.org/)\n",
    "\n",
    "- `dask_jobqueue.PBSCluster`\n",
    "- `dask_jobqueue.SlurmCluster`\n",
    "- `dask_jobqueue.LSFCluster`\n",
    "- etc.\n",
    "\n",
    "#### Dask MPI (https://mpi.dask.org/)\n",
    "\n",
    "- `dask_mpi.initialize`\n",
    "\n",
    "### Cloud\n",
    "\n",
    "#### Dask Kubernetes (https://kubernetes.dask.org/)\n",
    "\n",
    "- `dask_kubernetes.KubeCluster`\n",
    "\n",
    "#### Dask Cloud Provider (https://cloudprovider.dask.org)\n",
    "\n",
    "- `dask_cloudprovider.FargateCluster`\n",
    "- `dask_cloudprovider.ECSCluster`\n",
    "- `dask_cloudprovider.ECSCluster`\n",
    "\n",
    "#### Dask Gateway (https://gateway.dask.org/)\n",
    "\n",
    "- `dask_gateway.GatewayCluster`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45775347-0f7e-4882-a5a2-4bc0ce60791a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a4c70-964a-4667-b399-26e308ea4841",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "\n",
    "* Reference\n",
    "    *  [Docs](https://dask.org/)\n",
    "    *  [Examples](https://examples.dask.org/)\n",
    "    *  [Code](https://github.com/dask/dask/)\n",
    "    *  [Blog](https://blog.dask.org/)\n",
    "*  Ask for help\n",
    "    *   [`dask`](http://stackoverflow.com/questions/tagged/dask) tag on Stack Overflow, for usage questions\n",
    "    *   [github discussions](https://github.com/dask/dask/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues](https://github.com/dask/dask/issues/new) for bug reports and feature requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
